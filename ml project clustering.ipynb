{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Analysis\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "Problem 1:\n",
    "There are various stocks for which we have collected a data set, which all stocks are\n",
    "apparently similar in performance\n",
    "\n",
    "Problem 2:\n",
    "How many Unique patterns that exist in the historical stock data set, based on\n",
    "fluctuations in price.\n",
    "\n",
    "Problem 3:\n",
    "Identify which all stocks are moving together and which all stocks are different from\n",
    "each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stock = pd.read_csv('data_stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41266, 502)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SP500</th>\n",
       "      <th>NASDAQ.AAL</th>\n",
       "      <th>NASDAQ.AAPL</th>\n",
       "      <th>NASDAQ.ADBE</th>\n",
       "      <th>NASDAQ.ADI</th>\n",
       "      <th>NASDAQ.ADP</th>\n",
       "      <th>NASDAQ.ADSK</th>\n",
       "      <th>NASDAQ.AKAM</th>\n",
       "      <th>NASDAQ.ALXN</th>\n",
       "      <th>...</th>\n",
       "      <th>NYSE.WYN</th>\n",
       "      <th>NYSE.XEC</th>\n",
       "      <th>NYSE.XEL</th>\n",
       "      <th>NYSE.XL</th>\n",
       "      <th>NYSE.XOM</th>\n",
       "      <th>NYSE.XRX</th>\n",
       "      <th>NYSE.XYL</th>\n",
       "      <th>NYSE.YUM</th>\n",
       "      <th>NYSE.ZBH</th>\n",
       "      <th>NYSE.ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1491226200</td>\n",
       "      <td>2363.6101</td>\n",
       "      <td>42.3300</td>\n",
       "      <td>143.6800</td>\n",
       "      <td>129.6300</td>\n",
       "      <td>82.040</td>\n",
       "      <td>102.2300</td>\n",
       "      <td>85.2200</td>\n",
       "      <td>59.760</td>\n",
       "      <td>121.52</td>\n",
       "      <td>...</td>\n",
       "      <td>84.370</td>\n",
       "      <td>119.035</td>\n",
       "      <td>44.40</td>\n",
       "      <td>39.88</td>\n",
       "      <td>82.03</td>\n",
       "      <td>7.36</td>\n",
       "      <td>50.22</td>\n",
       "      <td>63.86</td>\n",
       "      <td>122.000</td>\n",
       "      <td>53.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1491226260</td>\n",
       "      <td>2364.1001</td>\n",
       "      <td>42.3600</td>\n",
       "      <td>143.7000</td>\n",
       "      <td>130.3200</td>\n",
       "      <td>82.080</td>\n",
       "      <td>102.1400</td>\n",
       "      <td>85.6500</td>\n",
       "      <td>59.840</td>\n",
       "      <td>121.48</td>\n",
       "      <td>...</td>\n",
       "      <td>84.370</td>\n",
       "      <td>119.035</td>\n",
       "      <td>44.11</td>\n",
       "      <td>39.88</td>\n",
       "      <td>82.03</td>\n",
       "      <td>7.38</td>\n",
       "      <td>50.22</td>\n",
       "      <td>63.74</td>\n",
       "      <td>121.770</td>\n",
       "      <td>53.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1491226320</td>\n",
       "      <td>2362.6799</td>\n",
       "      <td>42.3100</td>\n",
       "      <td>143.6901</td>\n",
       "      <td>130.2250</td>\n",
       "      <td>82.030</td>\n",
       "      <td>102.2125</td>\n",
       "      <td>85.5100</td>\n",
       "      <td>59.795</td>\n",
       "      <td>121.93</td>\n",
       "      <td>...</td>\n",
       "      <td>84.585</td>\n",
       "      <td>119.260</td>\n",
       "      <td>44.09</td>\n",
       "      <td>39.98</td>\n",
       "      <td>82.02</td>\n",
       "      <td>7.36</td>\n",
       "      <td>50.12</td>\n",
       "      <td>63.75</td>\n",
       "      <td>121.700</td>\n",
       "      <td>53.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1491226380</td>\n",
       "      <td>2364.3101</td>\n",
       "      <td>42.3700</td>\n",
       "      <td>143.6400</td>\n",
       "      <td>130.0729</td>\n",
       "      <td>82.000</td>\n",
       "      <td>102.1400</td>\n",
       "      <td>85.4872</td>\n",
       "      <td>59.620</td>\n",
       "      <td>121.44</td>\n",
       "      <td>...</td>\n",
       "      <td>84.460</td>\n",
       "      <td>119.260</td>\n",
       "      <td>44.25</td>\n",
       "      <td>39.99</td>\n",
       "      <td>82.02</td>\n",
       "      <td>7.35</td>\n",
       "      <td>50.16</td>\n",
       "      <td>63.88</td>\n",
       "      <td>121.700</td>\n",
       "      <td>53.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1491226440</td>\n",
       "      <td>2364.8501</td>\n",
       "      <td>42.5378</td>\n",
       "      <td>143.6600</td>\n",
       "      <td>129.8800</td>\n",
       "      <td>82.035</td>\n",
       "      <td>102.0600</td>\n",
       "      <td>85.7001</td>\n",
       "      <td>59.620</td>\n",
       "      <td>121.60</td>\n",
       "      <td>...</td>\n",
       "      <td>84.470</td>\n",
       "      <td>119.610</td>\n",
       "      <td>44.11</td>\n",
       "      <td>39.96</td>\n",
       "      <td>82.03</td>\n",
       "      <td>7.36</td>\n",
       "      <td>50.20</td>\n",
       "      <td>63.91</td>\n",
       "      <td>121.695</td>\n",
       "      <td>53.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE      SP500  NASDAQ.AAL  NASDAQ.AAPL  NASDAQ.ADBE  NASDAQ.ADI  \\\n",
       "0  1491226200  2363.6101     42.3300     143.6800     129.6300      82.040   \n",
       "1  1491226260  2364.1001     42.3600     143.7000     130.3200      82.080   \n",
       "2  1491226320  2362.6799     42.3100     143.6901     130.2250      82.030   \n",
       "3  1491226380  2364.3101     42.3700     143.6400     130.0729      82.000   \n",
       "4  1491226440  2364.8501     42.5378     143.6600     129.8800      82.035   \n",
       "\n",
       "   NASDAQ.ADP  NASDAQ.ADSK  NASDAQ.AKAM  NASDAQ.ALXN  ...  NYSE.WYN  NYSE.XEC  \\\n",
       "0    102.2300      85.2200       59.760       121.52  ...    84.370   119.035   \n",
       "1    102.1400      85.6500       59.840       121.48  ...    84.370   119.035   \n",
       "2    102.2125      85.5100       59.795       121.93  ...    84.585   119.260   \n",
       "3    102.1400      85.4872       59.620       121.44  ...    84.460   119.260   \n",
       "4    102.0600      85.7001       59.620       121.60  ...    84.470   119.610   \n",
       "\n",
       "   NYSE.XEL  NYSE.XL  NYSE.XOM  NYSE.XRX  NYSE.XYL  NYSE.YUM  NYSE.ZBH  \\\n",
       "0     44.40    39.88     82.03      7.36     50.22     63.86   122.000   \n",
       "1     44.11    39.88     82.03      7.38     50.22     63.74   121.770   \n",
       "2     44.09    39.98     82.02      7.36     50.12     63.75   121.700   \n",
       "3     44.25    39.99     82.02      7.35     50.16     63.88   121.700   \n",
       "4     44.11    39.96     82.03      7.36     50.20     63.91   121.695   \n",
       "\n",
       "   NYSE.ZTS  \n",
       "0    53.350  \n",
       "1    53.350  \n",
       "2    53.365  \n",
       "3    53.380  \n",
       "4    53.240  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41266 entries, 0 to 41265\n",
      "Columns: 502 entries, DATE to NYSE.ZTS\n",
      "dtypes: float64(501), int64(1)\n",
      "memory usage: 158.0 MB\n"
     ]
    }
   ],
   "source": [
    "data_stock.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cor = data_stock.copy()\n",
    "data_cor.drop(['DATE','SP500'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excersise 1:**\n",
    "> Which are stocks are apparently similar in nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding correlation between variables - identify highly correlated variables\n",
    "cor = data_cor.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_dt = pd.DataFrame(data=cor.values, columns=cor.index, index = cor.index)\n",
    "cor_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_dt[cor_dt['NASDAQ.AAL'].values > 0.80][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excersise 2:**\n",
    "> How many Unique patterns that exist in the historical stock data set, based on\n",
    "fluctuations in price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will try to find the optimal number of clusters and assign each stock to a specific cluster\n",
    "# Calculate the average annual percentage return and volatilities over a theoritical one year period\n",
    "\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "import numpy as np\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "returns = data.pct_change().mean()*252\n",
    "returns = pd.DataFrame(returns)\n",
    "returns.columns = ['Returns']\n",
    "returns.Volatility = data.pct_change().std()*sqrt(252)\n",
    "\n",
    "# format the data into numpy array to feed into K-means algorithm\n",
    "dta = np.asarray([np.asarray(returns.Returns), np.asarray(returns.Volatility)]).T\n",
    "\n",
    "X = dta\n",
    "distortions =[]\n",
    "for k in range(2,20):\n",
    "    k_means = KMeans(n_clusters = k)\n",
    "    k_means.fit(X)\n",
    "    distortions.append(k_means.inertia_)\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot(range(2,20),distortions)\n",
    "plt.grid(True)\n",
    "plt.title('Elbow-Curve')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above Elbow curve we see that the curve has a steep at cluster no.4 or 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import plot, show\n",
    "# Computing kmeans with K =5 (5 clusters)\n",
    "centroids,_= kmeans(dta, 5)\n",
    "# Assign each sample to a cluster\n",
    "idx,_ = vq(dta, centroids)\n",
    "\n",
    "# some plotting using numpy's logical indexing\n",
    "plot(dta[idx==0,0],dta[idx==0,1],'ob',\n",
    "     dta[idx==1,0],dta[idx==1,1],'oy',\n",
    "     dta[idx==2,0],dta[idx==2,1],'or',\n",
    "     dta[idx==3,0],dta[idx==3,1],'og',\n",
    "     dta[idx==4,0],dta[idx==4,1],'om')\n",
    "plot(centroids[:,0],centroids[:,1],'sg',markersize=8)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like we have an outlier in the data which is skewing the results and making it difficult to actually see what is going on for all the other stocks. Let’s take the easy route and just delete the outlier from our data set and run this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify the outlier\n",
    "print(returns.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so let’s drop the stock ‘BHF and recreate the necessary data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the relevant stock from our data\n",
    "data.drop(['NYSE.XRX','DATE','SP500'],inplace=True,axis=1)\n",
    "\n",
    "returns = data.pct_change().mean()*252\n",
    "returns = pd.DataFrame(returns)\n",
    "returns.columns = ['Returns']\n",
    "returns.Volatility = data.pct_change().std()*sqrt(252)\n",
    "\n",
    "# format the data into numpy array to feed into K-means algorithm\n",
    " \n",
    "#recreate data to feed into the algorithm\n",
    "dta = np.asarray([np.asarray(returns.Returns), np.asarray(returns.Volatility)]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing kmeans with K =5 (5 clusters)\n",
    "centroids,_= kmeans(dta, 5)\n",
    "# Assign each sample to a cluster\n",
    "idx,_ = vq(dta, centroids)\n",
    "\n",
    "# some plotting using numpy's logical indexing\n",
    "plot(dta[idx==0,0],dta[idx==0,1],'ob',\n",
    "     dta[idx==1,0],dta[idx==1,1],'oy',\n",
    "     dta[idx==2,0],dta[idx==2,1],'or',\n",
    "     dta[idx==3,0],dta[idx==3,1],'og',\n",
    "     dta[idx==4,0],dta[idx==4,1],'om')\n",
    "plot(centroids[:,0],centroids[:,1],'sg',markersize=8)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally to get the details of which stock is actually in which cluster we can run the following line of code to carry out a list comprehension to create a list of tuples in the (Stock Name, Cluster Number) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = [(name,cluster) for name, cluster in zip(returns.index,idx)]\n",
    "details[:5]\n",
    "#for detail in details:\n",
    "#   print(list(detail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there you have it, we now have a list of each of the stocks in the S&P 500, along with which one of 5 clusters they belong to with the clusters being defined by their return and volatility characteristics. We also have a visual representation of the clusters in chart format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(details, columns=['Stock_Name','Cluster_No'])\n",
    "df.Cluster_No.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ind = df.Cluster_No.value_counts()\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(x=ind.index, y=ind.values, alpha=0.6)\n",
    "plt.ylabel('Number of Occurences',fontsize=12)\n",
    "plt.xlabel('Cluster Number',fontsize=12)\n",
    "plt.title('Barplot - Indicator',fontsize =16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 3 PCA:**\n",
    "> Identify which all stocks are moving together and which all stocks are different from\n",
    "each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to identify the stocks correlated with each other\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data.copy()\n",
    "dt.drop(['DATE','SP500'],inplace=True,axis=1)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# convert data into numpy arrays\n",
    "X = dt.values\n",
    "\n",
    "# Scaling the values\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=150)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# the amount of variance that each PCA explains\n",
    "var = pca.explained_variance_ratio_\n",
    "\n",
    "# cumulative varince explains\n",
    "var1 = np.cumsum(np.round(var, decimals=4)*100)\n",
    "print(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at above plot I can consider 25 variables \n",
    "pca = PCA(n_components =25)\n",
    "X1 = pca.fit_transform(X_scaled)\n",
    "print(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of PCA :',len(pca.components_))\n",
    "print(abs(pca.components_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame(pca.components_, columns = dt.columns)\n",
    "comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
